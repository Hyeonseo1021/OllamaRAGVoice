import chromadb
import re
import pandas as pd
from sentence_transformers import SentenceTransformer

# âœ… ChromaDB í´ë¼ì´ì–¸íŠ¸ ì„¤ì •
chroma_client = chromadb.HttpClient(host="localhost", port=8000)
collection = chroma_client.get_or_create_collection(name="data_files")  # CSV/JSON ë°ì´í„° ì €ì¥ ì»¬ë ‰ì…˜

embedding_model = SentenceTransformer("all-MiniLM-L6-v2")

def extract_matching_columns(prompt: str, column_names: list) -> dict:
    """
    ğŸ“Œ ì‚¬ìš©ì ì§ˆë¬¸ì—ì„œ ë°ì´í„°ì˜ ì—´(column)ê³¼ ê°’(value)ì„ ì¶”ì¶œí•˜ì—¬ ë§¤ì¹­
    ğŸ”¥ "ë†ê°€ 2" ê°™ì€ í‘œí˜„ì´ ìˆìœ¼ë©´, "ë†ê°€"ëŠ” ì—´, "2"ëŠ” ê°’ìœ¼ë¡œ ì„¤ì •
    ğŸ”¥ ê°’ì´ ì—†ëŠ” ê²½ìš°(None)ëŠ” í•´ë‹¹ ì—´ì´ ì¡´ì¬í•˜ëŠ”ì§€ë§Œ í™•ì¸
    """
    matched_columns = {}

    # âœ… ì •ê·œì‹ì„ ì´ìš©í•˜ì—¬ "ë†ê°€ 2" ê°™ì€ í˜•íƒœì—ì„œ ìˆ«ìì™€ í…ìŠ¤íŠ¸ë¥¼ ë¶„ë¦¬
    word_number_pattern = re.findall(r"([ê°€-í£A-Za-z]+)\s*([\d]+)", prompt)  # (ë‹¨ì–´, ìˆ«ì) ë§¤ì¹­

    for word, number in word_number_pattern:
        for col in column_names:
            if word in col:  # ğŸ”¥ ì§ˆë¬¸ ì† í‚¤ì›Œë“œê°€ ë°ì´í„° ì—´ê³¼ ë§¤ì¹­ë˜ë©´ ì¶”ê°€
                matched_columns[col] = number  # ğŸ”¥ ìˆ«ìë¥¼ ê°’(value)ìœ¼ë¡œ ì„¤ì •

    # âœ… ìˆ«ìê°€ ì—†ëŠ” ì¼ë°˜ í‚¤ì›Œë“œ ì²˜ë¦¬
    for col in column_names:
        for word in prompt.split():
            if word in col and col not in matched_columns:  # ğŸ”¥ ê¸°ì¡´ì— ë§¤ì¹­ë˜ì§€ ì•Šì€ ê²½ìš°ë§Œ ì¶”ê°€
                matched_columns[col] = None

    return matched_columns

def convert_to_dict(raw_data):
    """
    ğŸ“Œ ë¬¸ìì—´ ë°ì´í„°ë¥¼ JSON(dict) í˜•íƒœë¡œ ë³€í™˜
    """
    processed_data = []
    for entry in raw_data:
        data_dict = {}
        for field in entry.split(", "):  # ê° í•„ë“œ ë¶„ë¦¬
            key_value = field.split(": ")
            if len(key_value) == 2:
                key, value = key_value
                data_dict[key.strip()] = value.strip()
        processed_data.append(data_dict)
    return processed_data

def filter_growth_data(raw_data: list, prompt: str) -> list:
    """
    ğŸ“Œ ì‚¬ìš©ì ì§ˆë¬¸ì—ì„œ ë§¤ì¹­ëœ ì—´ê³¼ ê°’ìœ¼ë¡œ ë°ì´í„° í•„í„°ë§
    ğŸ”¥ íŠ¹ì • ì—´(ì˜ˆ: "ë†ê°€ 2")ì´ ìˆë‹¤ë©´, í•´ë‹¹ ì—´ì„ ë¨¼ì € í•„í„°ë§í•˜ì—¬ ê²€ìƒ‰ ë²”ìœ„ ì¶•ì†Œ
    ğŸ”¥ ê°’ì´ ì—†ëŠ” ê²½ìš°(None)ëŠ” í•´ë‹¹ ì—´ì´ ì¡´ì¬í•˜ëŠ”ì§€ë§Œ í™•ì¸
    """
    try:
        if not raw_data:
            return []

        # âœ… ë¬¸ìì—´ ë°ì´í„°ë¥¼ JSON(dict) í˜•íƒœë¡œ ë³€í™˜
        processed_data = convert_to_dict(raw_data)
        df = pd.DataFrame(processed_data)  # DataFrame ë³€í™˜
        column_names = df.columns.tolist()

        # âœ… ì‚¬ìš©ì ì§ˆë¬¸ì—ì„œ ë°ì´í„°ì™€ ë§¤ì¹­ë˜ëŠ” ì—´ê³¼ ê°’ ì°¾ê¸°
        matching_filters = extract_matching_columns(prompt, column_names)
        print(f"ğŸ” í•„í„°ë§ ì¡°ê±´: {matching_filters}")

        # âœ… 1ï¸âƒ£ íŠ¹ì •í•œ ê°’(ì˜ˆ: "ë†ê°€ 2")ì´ ìˆëŠ” ê²½ìš°, ë¨¼ì € í•„í„°ë§í•˜ì—¬ ë°ì´í„° ì¶•ì†Œ
        for col, value in matching_filters.items():
            if col in df.columns and value is not None:
                df = df[df[col].astype(str) == value]  # ğŸ”¥ ê°’ì´ ìˆëŠ” ê²½ìš° ì •í™•í•œ ë§¤ì¹­

        # âœ… 2ï¸âƒ£ ê°’ì´ Noneì¸ ê²½ìš°, í•´ë‹¹ ì—´ì´ ì¡´ì¬í•˜ëŠ”ì§€ë§Œ í™•ì¸
        for col, value in matching_filters.items():
            if col in df.columns and value is None:
                df = df[df[col].notna()]

        # âœ… í•„í„°ë§ ê²°ê³¼ê°€ ì—†ëŠ” ê²½ìš° ìœ ì‚¬í•œ ë°ì´í„° ì¶”ì²œ
        if df.empty:
            print("âš  ì •í™•í•œ ë°ì´í„°ê°€ ì—†ìŒ â†’ ìœ ì‚¬í•œ ë°ì´í„° ì¶”ì²œ")
            return processed_data  # ì›ë³¸ ë°ì´í„°ë¥¼ ë°˜í™˜í•˜ì—¬ ë‹¤ë¥¸ ì¡°ê±´ìœ¼ë¡œ ì¬ê²€ìƒ‰ ê°€ëŠ¥

        return df.to_dict(orient="records")

    except Exception as e:
        print(f"âŒ ë°ì´í„° í•„í„°ë§ ì˜¤ë¥˜: {e}")
        return []

def search_growth_data_in_chromadb(prompt: str) -> list:
    """
    ğŸ“Œ ChromaDBì—ì„œ ë°ì´í„°ë¥¼ ê²€ìƒ‰í•˜ê¸° ì „ì— filter_growth_dataë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì—¬,
       í•„í„°ë§ëœ ë°ì´í„°ê°€ ì¶©ë¶„í•˜ë©´ ê·¸ëŒ€ë¡œ ë°˜í™˜, ë¶€ì¡±í•˜ë©´ ì¶”ê°€ ê²€ìƒ‰ ìˆ˜í–‰
    """
    try:
        # âœ… ChromaDBì—ì„œ ì „ì²´ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
        raw_data = collection.get()["documents"]  # ì „ì²´ ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°
        
        # âœ… ë¨¼ì € í•„í„°ë§ ì‹¤í–‰ (ì§ˆë¬¸ê³¼ ì—°ê´€ëœ ë°ì´í„°ë§Œ ì¶”ì¶œ)
        filtered_data = filter_growth_data(raw_data, prompt)

        # âœ… í•„í„°ë§ëœ ë°ì´í„°ê°€ ì¶©ë¶„í•˜ë©´ ë°”ë¡œ ë°˜í™˜
        if filtered_data and len(filtered_data) < 1000:  
            print(f"âœ… í•„í„°ë§ëœ ë°ì´í„° ê°œìˆ˜: {len(filtered_data)} â†’ ì§ì ‘ ë°˜í™˜")
            return filtered_data
        
        print("âš  í•„í„°ë§ëœ ë°ì´í„°ê°€ ë¶€ì¡±í•˜ì—¬ ChromaDB ê²€ìƒ‰ ìˆ˜í–‰")

        # âœ… ChromaDBì—ì„œ ê²€ìƒ‰ ìˆ˜í–‰ (í•„í„°ë§ëœ ë°ì´í„°ê°€ ë„ˆë¬´ ì ì„ ë•Œ)
        query_embedding = embedding_model.encode(prompt).tolist()
        
        max_results = 500  # ì´ˆê¸° ê²€ìƒ‰ ê°œìˆ˜
        MAX_LIMIT = 10_000  # ìµœëŒ€ ê²€ìƒ‰ ê°œìˆ˜
        retrieved_docs = []

        while max_results <= MAX_LIMIT:
            print(f"ğŸ” {max_results}ê°œ ê²€ìƒ‰ ì‹œë„ ì¤‘...")

            results = collection.query(
                query_embeddings=[query_embedding],  
                n_results=max_results
            )

            retrieved_docs = results.get("documents", [[]])[0]
            print(f"ğŸ“Œ í˜„ì¬ ê²€ìƒ‰ëœ ë°ì´í„° ê°œìˆ˜: {len(retrieved_docs)}")

            if retrieved_docs:
                return retrieved_docs  # ğŸ”¥ í•„í„°ë§ í›„ ê²€ìƒ‰ëœ ë°ì´í„° ë°˜í™˜

            print("âŒ ê²€ìƒ‰ëœ ë°ì´í„°ê°€ ì—†ìŒ â†’ ê²€ìƒ‰ ê°œìˆ˜ ì¦ê°€ ì‹œë„")
            max_results *= 2  # âœ… ê²€ìƒ‰ ê°œìˆ˜ ì¦ê°€

        print("âš  ìµœëŒ€ ê²€ìƒ‰ ê°œìˆ˜ì— ë„ë‹¬í–ˆì§€ë§Œ ì›í•˜ëŠ” ë°ì´í„°ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        return []

    except Exception as e:
        print(f"âŒ ChromaDB ë°ì´í„° ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
        return []
