import ollama
from services.rag import retrieve_relevant_text, should_apply_rag  # ğŸ”¥ ë³€ê²½ëœ ë™ì  RAG í•¨ìˆ˜

# âœ… íŠ¹ì • ì§ˆë¬¸ì—ì„œë§Œ RAGë¥¼ ì ìš©í•˜ëŠ” ë¡œì§
async def query_olama(prompt: str) -> str:
    """ì‚¬ìš©ì ì…ë ¥ì„ ê¸°ë°˜ìœ¼ë¡œ í•„ìš”í•œ ê²½ìš°ì—ë§Œ RAGë¥¼ ì ìš©í•˜ì—¬ Olama ëª¨ë¸ í˜¸ì¶œ"""

    # ğŸ”¹ íŠ¹ì • í‚¤ì›Œë“œê°€ í¬í•¨ëœ ê²½ìš°ì—ë§Œ RAG ì ìš©
    if should_apply_rag(prompt):
        print("ğŸ” RAG ì ìš©: ì‹¤ì‹œê°„ ì›¹ ê²€ìƒ‰ ìˆ˜í–‰ ì¤‘...")
        context = retrieve_relevant_text(prompt)  # ğŸ”¥ ê²€ìƒ‰ ìˆ˜í–‰
        context = context[:500]
        query_text = f"Context: {context}\nUser: {prompt}"
    else:
        print("ğŸ’¡ RAG ë¯¸ì ìš©: ì¼ë°˜ Olama ëª¨ë¸ ì‹¤í–‰")
        query_text = prompt  # ì¼ë°˜ ì§ˆë¬¸ì€ ê²€ìƒ‰ ì—†ì´ Olama ì‹¤í–‰

    # ğŸ§  Olama ëª¨ë¸ í˜¸ì¶œ
    response = ollama.chat(model="mistral", messages=[
        {"role": "system", "content": "You are a knowledgeable assistant."},
        {"role": "user", "content": query_text}
    ])

    # âœ… ì‘ë‹µì´ `Message` ê°ì²´ì´ë¯€ë¡œ `.message.content` ì‚¬ìš©
    if hasattr(response, "message") and hasattr(response.message, "content"):
        return response.message.content

    return "Error: Could not retrieve response from Olama"
