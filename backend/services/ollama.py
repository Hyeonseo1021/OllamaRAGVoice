import ollama
from services.rag import should_apply_rag, search_web

async def query_olama(prompt: str, use_rag: bool = False, threshold: float = 0.7) -> str:
    """ğŸ“š RAG ë²„íŠ¼ ì ìš© ì‹œ ë¬¸ì„œ ê²€ìƒ‰ í›„ ìœ ì‚¬ë„ íŒë‹¨í•˜ì—¬ ChromaDB or ì›¹ ê²€ìƒ‰ ì‚¬ìš©"""

    if use_rag:
        # ğŸ” ChromaDB ë¬¸ì„œ ê²€ìƒ‰ ìˆ˜í–‰
        use_rag, context = should_apply_rag(prompt, top_k_final=20, threshold=threshold)

        if use_rag:
            print("âœ… RAG ì ìš©: ChromaDB ê²€ìƒ‰ ê²°ê³¼ í™œìš©")
            print(f"ğŸ” ì‚¬ìš©ëœ ì»¨í…ìŠ¤íŠ¸ ë‚´ìš©: {context[:500]}...")  # âœ… ì»¨í…ìŠ¤íŠ¸ í™•ì¸ìš© ì¶œë ¥

            # âœ… ChromaDB ë¬¸ì„œë¥¼ í™œìš©í•œ ë‹µë³€ í”„ë¡¬í”„íŠ¸
            query_text = f"""
            ë‹¹ì‹ ì€ ì „ë¬¸ì ì¸ AI ë¹„ì„œì´ë©°, ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•´ í•­ìƒ ê³µì†í•œ ì¡´ëŒ“ë§ì„ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤.
            ë˜í•œ, ì‘ë‹µì€ ê¸°ë³¸ì ìœ¼ë¡œ í•œêµ­ì–´ë¡œ ì‘ì„±ë˜ì§€ë§Œ, íŠ¹ì • ê¸°ìˆ  ìš©ì–´ë‚˜ ë…¼ë¬¸ ê°œë…ì€ ì˜ì–´ë¡œ ìœ ì§€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
            ì‘ë‹µì˜ ì „ì²´ì ì¸ íë¦„ì€ ìì—°ìŠ¤ëŸ½ê³  ì¼ê´€ë˜ë„ë¡ ìœ ì§€í•´ì•¼ í•©ë‹ˆë‹¤.
            ë‹¤ìŒ ì»¨í…ìŠ¤íŠ¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì‚¬ìš©ì ì§ˆë¬¸ì— ë‹µë³€í•˜ì„¸ìš”.

            ### Context:
            {context}

            ### User Question:
            {prompt}

            ### Assistant Response:
            """

        else:
            print("âŒ ë¬¸ì„œ ìœ ì‚¬ë„ ë‚®ìŒ â†’ ì›¹ ê²€ìƒ‰ ìˆ˜í–‰")
            context = search_web(prompt) or "No relevant documents found."

            # âœ… ì›¹ ê²€ìƒ‰ì„ í™œìš©í•œ ë‹µë³€ í”„ë¡¬í”„íŠ¸
            query_text = f"""
            ë‹¹ì‹ ì€ AI ë¹„ì„œì´ë©°, ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•´ í•­ìƒ ê³µì†í•œ ì¡´ëŒ“ë§ì„ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤.
            ë˜í•œ, ì‘ë‹µì€ ê¸°ë³¸ì ìœ¼ë¡œ í•œêµ­ì–´ë¡œ ì‘ì„±ë˜ì–´ì•¼ í•˜ì§€ë§Œ, íŠ¹ì • ê¸°ìˆ  ìš©ì–´ë‚˜ ë…¼ë¬¸ ê°œë…ì€ ì˜ì–´ë¡œ ìœ ì§€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

            ë‹¤ìŒì€ ì›¹ ê²€ìƒ‰ì„ í†µí•´ ì–»ì€ ì •ë³´ì…ë‹ˆë‹¤. ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ë‹µë³€ì„ ì œê³µí•˜ì„¸ìš”.

            ### Web Search Results:
            {context}

            ### User Question:
            {prompt}

            ### Assistant Response:
            """

    else:
        print("ğŸ’¡ RAG ë²„íŠ¼ OFF â†’ ì¼ë°˜ ëª¨ë¸ ì‘ë‹µ")
        query_text = prompt  # ê·¸ëƒ¥ Olama ëª¨ë¸ ì‚¬ìš©

    # ğŸ§  Olama ëª¨ë¸ í˜¸ì¶œ
    response = ollama.chat(model="mistral", messages=[
        {"role": "system", "content": "You are a professional AI assistant providing polite and consistent answers in Korean."},
        {"role": "user", "content": query_text}
    ])

    # âœ… ì‘ë‹µì´ `Message` ê°ì²´ì´ë¯€ë¡œ `.message.content` ì‚¬ìš©
    if hasattr(response, "message") and hasattr(response.message, "content"):
        return response.message.content

    return "Error: Could not retrieve response from Olama"
