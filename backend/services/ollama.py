import ollama
from services.rag import should_apply_rag, search_web

async def query_olama(prompt: str, use_rag: bool = False, threshold: float = 0.7) -> str:
    """ğŸ“š RAG ë²„íŠ¼ ì ìš© ì‹œ ë¬¸ì„œ ê²€ìƒ‰ í›„ ìœ ì‚¬ë„ íŒë‹¨í•˜ì—¬ ChromaDB or ì›¹ ê²€ìƒ‰ ì‚¬ìš©"""

    if use_rag:
        # ğŸ” ChromaDB ë¬¸ì„œ ê²€ìƒ‰ ìˆ˜í–‰
        use_rag, context = should_apply_rag(prompt, top_k_final=20, threshold=threshold)

        if use_rag:
            print("âœ… RAG ì ìš©: ChromaDB ê²€ìƒ‰ ê²°ê³¼ í™œìš©")
            print(f"ğŸ” ì‚¬ìš©ëœ ì»¨í…ìŠ¤íŠ¸ ë‚´ìš©: {context[:500]}...")  # âœ… ì»¨í…ìŠ¤íŠ¸ í™•ì¸ìš© ì¶œë ¥

            # âœ… ChromaDB ë¬¸ì„œë¥¼ í™œìš©í•œ ë‹µë³€ í”„ë¡¬í”„íŠ¸
            query_text = f"""
            ë‹¹ì‹ ì€ **ì¼ê´€ë˜ê³  ì •ì¤‘í•œ í•œêµ­ì–´ ë‹µë³€ì„ ì œê³µí•˜ëŠ” ì „ë¬¸ê°€ AI ì–´ì‹œìŠ¤í„´íŠ¸**ì…ë‹ˆë‹¤.
            í•­ìƒ ê³µì‹ì ì¸ í•œêµ­ì–´(ì¡´ëŒ“ë§)ë¡œ ì‘ë‹µí•˜ì‹­ì‹œì˜¤.
            ê¸°ìˆ ì  ë˜ëŠ” ê³¼í•™ì  ìš©ì–´ì— ì¼ë°˜ì ìœ¼ë¡œ ì‚¬ìš©ë˜ëŠ” í•œêµ­ì–´ ë²ˆì—­ì´ ìˆë‹¤ë©´ í•´ë‹¹ í•œêµ­ì–´ ìš©ì–´ë¥¼ ì‚¬ìš©í•˜ì‹­ì‹œì˜¤.
            ì ì ˆí•œ í•œêµ­ì–´ ë²ˆì—­ì´ ì—†ì„ ê²½ìš° ì˜ì–´ ìš©ì–´ë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ì‹­ì‹œì˜¤.
            í•œêµ­ì–´ì™€ ì˜ì–´ê°€ ëª¨ë‘ ì¼ë°˜ì ìœ¼ë¡œ ì‚¬ìš©ë˜ëŠ” ê²½ìš°, ë‘˜ ë‹¤ ì œê³µí•˜ì‹­ì‹œì˜¤.

            **ì œê³µëœ ë¬¸ë§¥ì„ ê¸°ë°˜ìœ¼ë¡œ í•œêµ­ì–´ë¡œë§Œ ì‘ë‹µì„ ìƒì„±í•˜ì‹­ì‹œì˜¤.** ë²ˆì—­ëœ ì‘ë‹µì„ ì¶”ê°€ë¡œ ì œê³µí•˜ì§€ ë§ˆì‹­ì‹œì˜¤.
            ë¬¸ë§¥ì— ê´€ë ¨ ì •ë³´ê°€ í¬í•¨ë˜ì§€ ì•Šì•˜ë‹¤ë©´, ë‹¤ìŒê³¼ ê°™ì´ ì‘ë‹µí•˜ì‹­ì‹œì˜¤: "ì¶©ë¶„í•œ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤."

            ### Context:
            {context}

            ### User Question:
            {prompt}

            ### Assistant Response (in Korean):
            """

        else:
            print("âŒ ë¬¸ì„œ ìœ ì‚¬ë„ ë‚®ìŒ â†’ ì›¹ ê²€ìƒ‰ ìˆ˜í–‰")
            context = search_web(prompt) or "No relevant documents found."

            # âœ… ì›¹ ê²€ìƒ‰ì„ í™œìš©í•œ ë‹µë³€ í”„ë¡¬í”„íŠ¸ (ë” ë³´ìˆ˜ì ì¸ ë‹µë³€)
            query_text = f"""
            You are an AI assistant that provides **formal and polite responses in Korean**.
            Your answers should always be in **Korean (ì¡´ëŒ“ë§)**.
            If a technical or scientific term has a commonly used Korean translation, use the Korean term.
            If there is no suitable Korean translation, use the English term.
            If both Korean and English are commonly used, provide both (e.g., "Brain-Derived Neurotrophic Factor (BDNF), ë‡Œìœ ë˜ ì‹ ê²½ì˜ì–‘ì¸ì").

            The following information is from a web search. Based on this, provide a reliable response.

            ### Web Search Results:
            {context}

            ### User Question:
            {prompt}

            ### Assistant Response (in Korean):
            """

    else:
        print("ğŸ’¡ RAG ë²„íŠ¼ OFF â†’ ì¼ë°˜ ëª¨ë¸ ì‘ë‹µ")
        query_text = prompt  # ê·¸ëƒ¥ Olama ëª¨ë¸ ì‚¬ìš©

    # ğŸ§  Olama ëª¨ë¸ í˜¸ì¶œ
    response = ollama.chat(model="mistral", messages=[
        {"role": "system", "content": "You are a professional AI assistant providing polite and consistent answers in Korean."},
        {"role": "user", "content": query_text}
    ])

    # âœ… ì‘ë‹µì´ `Message` ê°ì²´ì´ë¯€ë¡œ `.message.content` ì‚¬ìš©
    if hasattr(response, "message") and hasattr(response.message, "content"):
        return response.message.content

    return "Error: Could not retrieve response from Olama"
