import sys
import ollama
from langchain.agents import initialize_agent, AgentType
from langchain.tools import Tool
from langchain_ollama import OllamaLLM  # âœ… LangChain Ollama ì§€ì› LLM ì¶”ê°€
from langchain.prompts import PromptTemplate
from langchain.agents.agent import AgentExecutor
from agents.data_tool import data_tool
from agents.rag_tool import rag_tool
from agents.both_tool import both_tool
from agents.unknown_tool import unknown_tool

llm_context = OllamaLLM(model="mistral")  
llm_response = OllamaLLM(model="gemma:7b")

# âœ… 2ï¸âƒ£ LangChain Tool ì„¤ì •
tools = [data_tool, rag_tool, both_tool, unknown_tool]

context_agent = initialize_agent(
    tools=tools,
    llm=llm_context,
    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,
    verbose=True,
    handle_parsing_errors=True,
    max_iterations=5,
    allow_ask_for_clarification=False
)

# âœ… 3ï¸âƒ£ LangChainì—ì„œ ì‚¬ìš©í•  PromptTemplate ìƒì„± (í•„ìˆ˜ ë³€ìˆ˜ í¬í•¨)
prompt_template = PromptTemplate(
    input_variables=["prompt", "agent_scratchpad", "intermediate_steps", "context"],
    template="""
        You are a structured reasoning agent with access to specific tools.
        Your job is to choose exactly ONE appropriate tool and provide the result in a strict format.

        ---

        ### ğŸ§¾ User Query:
        {prompt}

        ### ğŸ“š Retrieved Context:
        {context}

        ### ğŸ§  Internal Scratchpad:
        {agent_scratchpad}

        ### â›“ï¸ Intermediate Steps:
        {intermediate_steps}

        ---

        ### ğŸ”§ Available Tools:

        - ğŸ§  **SmartFarmRAG**  
        â†’ ì‚¬ìš© ëª©ì : ì‘ë¬¼ í’ˆì¢…, ë³‘í•´ì¶©, ì¬ë°°ë²•, ë†ì—… ì§€ì‹ ì§ˆë¬¸  
        â†’ ì˜ˆì‹œ: â€œë”¸ê¸° í’ˆì¢… ì•Œë ¤ì¤˜â€, â€œê³ ì¶” ë³‘í•´ì¶©ì€ ë­ê°€ ìˆì–´?â€

        - ğŸŒ¡ **SmartFarmData**  
        â†’ ì‚¬ìš© ëª©ì : ì„¼ì„œ ê¸°ë°˜ ì‹¤ì‹œê°„ ë°ì´í„°(ì˜¨ë„, ìŠµë„, COâ‚‚, ì¡°ë„, í† ì–‘ ìˆ˜ë¶„ ë“±)  
        â†’ **ì§ˆë¬¸ì— 'í˜„ì¬', 'ì˜¤ëŠ˜', 'ì§€ê¸ˆ', ì„¼ì„œ ì´ë¦„'ì´ ëª…ì‹œë˜ì–´ ìˆì–´ì•¼ í•¨**

        - ğŸ§ª **SmartFarmBOTH**  
        â†’ ì‚¬ìš© ëª©ì : ì„¼ì„œ ë°ì´í„°ì™€ ë¬¸ì„œ ì •ë³´ë¥¼ ë¹„êµí•˜ê±°ë‚˜ í†µí•© ì§ˆë¬¸ ì‹œ  
        â†’ ì˜ˆì‹œ: â€œì§€ê¸ˆ ì˜¨ë„ê°€ í† ë§ˆí†  ìƒì¥ì— ì ì ˆí•´?â€

        - â“ **SmartFarmUnknown**  
        â†’ ì‚¬ìš© ëª©ì : ë†ì—…/ì„¼ì„œì™€ ê´€ë ¨ ì—†ëŠ” ì¼ë°˜ ëŒ€í™”, ë˜ëŠ” ë¶„ë¥˜ ë¶ˆê°€ëŠ¥í•œ ì§ˆë¬¸  
        â†’ ì˜ˆì‹œ: â€œGPTëŠ” ë‡Œê°€ ìˆë‚˜ìš”?â€, â€œë‚´ì¼ ë­ í• ê¹Œ?â€

        ---

        ### ğŸ›‘ Strict Usage Rules:

        - âœ… ë°˜ë“œì‹œ í•˜ë‚˜ì˜ ë„êµ¬ë§Œ ì„ íƒ
        - ğŸš« "ë”¸ê¸° í’ˆì¢…", "ê³ ì¶” ë³‘í•´ì¶©" ê°™ì€ ì¼ë°˜ ë†ì—… ì§ˆë¬¸ì—ëŠ” **ì ˆëŒ€ SmartFarmData ì‚¬ìš© ê¸ˆì§€**
        - ğŸš« ë¬¸ì„œ ê²€ìƒ‰ ì‹¤íŒ¨ ì‹œ SmartFarmDataë¥¼ fallbackìœ¼ë¡œ ì‚¬ìš©í•˜ì§€ ë§ ê²ƒ
        - ğŸš« ë„êµ¬ í˜¸ì¶œ ì‹¤íŒ¨ ì‹œ ë‹¤ë¥¸ ë„êµ¬ ì‹œë„ ê¸ˆì§€
        - ğŸš« ë„êµ¬ í˜¸ì¶œ ì—†ì´ ë‹µí•˜ì§€ ë§ ê²ƒ (Final AnswerëŠ” context ê¸°ë°˜ì¼ ë•Œë§Œ)

        ---

        ### âœ… Output Format:

        ë°˜ë“œì‹œ ì•„ë˜ í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•˜ì‹­ì‹œì˜¤. ìˆœì„œì™€ íƒœê·¸ëŠ” **ì ˆëŒ€ ë³€ê²½ ê¸ˆì§€**:

        Thought: [ë‚´ë¶€ íŒë‹¨ ì„¤ëª…]  
        Action: [SmartFarmRAG, SmartFarmData, SmartFarmBOTH, SmartFarmUnknown, or Final Answer]  
        Action Input: [ë„êµ¬ ì…ë ¥ or ìµœì¢… í•œêµ­ì–´ ì‘ë‹µ]

        ---

        ### âœ… Valid Example:

        Thought: The user is asking for strawberry varieties, which is a knowledge query.  
        Action: SmartFarmRAG  
        Action Input: ë”¸ê¸° í’ˆì¢…

        ---

        ğŸš¨ **ì´ í˜•ì‹ì„ ìœ„ë°˜í•  ê²½ìš° ì‹œìŠ¤í…œì€ ë™ì‘í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.**
        """
)

# âœ… response_agent Prompt
response_prompt = PromptTemplate(
    input_variables=["context", "prompt"],
    template="""
    í•­ìƒ ì •ì¤‘í•˜ê³  ì •í™•í•œ í•œêµ­ì–´ë¡œ ì‘ë‹µí•˜ì‹­ì‹œì˜¤.
    ì œê³µëœ ë¬¸ë§¥(context)ì„ ê¸°ë°˜ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ê³ , ê·¸ ì™¸ ì •ë³´ëŠ” ì ˆëŒ€ í¬í•¨í•˜ì§€ ë§ˆì‹­ì‹œì˜¤.

    ### ë¬¸ë§¥:
    {context}

    ### ì‚¬ìš©ì ì§ˆë¬¸:
    {prompt}

    ### ì‘ë‹µ:
    """
)

# âœ… ì‘ë‹µ ìƒì„± ì „ìš© Agent
response_agent = response_prompt | llm_response

# âœ… ë‘ Agentë¥¼ ì—°ê²°í•˜ëŠ” í•¨ìˆ˜
async def query_dual_agent(prompt: str) -> str:
    try:
        # Step 1: context ìˆ˜ì§‘
        context_result = context_agent.invoke({
            "input": prompt,
        })
        context = context_result["output"] if isinstance(context_result, dict) and "output" in context_result else str(context_result)
        print(f"ğŸ“„ë¬¸ë§¥ (ì•ë¶€ë¶„): {context[:500]}")
    except Exception as e:
        return f"âŒ context_agent ì˜¤ë¥˜: {e}"

    try:
        # Step 2: ì‘ë‹µ ìƒì„±
        response_text = response_agent.invoke({
            "context": context,
            "prompt": prompt
        })
        return response_text
    except Exception as e:
        return f"âŒ response_agent ì˜¤ë¥˜: {e}"